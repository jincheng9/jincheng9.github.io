<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>ChatGPT最佳实践系列-第3篇 - Jincheng9&#39;s blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="jincheng9" /><meta name="description" content="ChatGPT最佳实践系列-第3篇" /><meta name="keywords" content="chatgpt" />






<meta name="generator" content="Hugo 0.84.4 with theme even" />


<link rel="canonical" href="http://jincheng9.github.io/post/chatgpt-11/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="ChatGPT最佳实践系列-第3篇" />
<meta property="og:description" content="ChatGPT最佳实践系列-第3篇" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://jincheng9.github.io/post/chatgpt-11/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-09-02T14:36:16+08:00" />
<meta property="article:modified_time" content="2023-09-02T14:36:16+08:00" />

<meta itemprop="name" content="ChatGPT最佳实践系列-第3篇">
<meta itemprop="description" content="ChatGPT最佳实践系列-第3篇"><meta itemprop="datePublished" content="2023-09-02T14:36:16+08:00" />
<meta itemprop="dateModified" content="2023-09-02T14:36:16+08:00" />
<meta itemprop="wordCount" content="1972">
<meta itemprop="keywords" content="chatgpt," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="ChatGPT最佳实践系列-第3篇"/>
<meta name="twitter:description" content="ChatGPT最佳实践系列-第3篇"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">无忌</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">全部文章</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">无忌</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">全部文章</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">ChatGPT最佳实践系列-第3篇</h1>

      <div class="post-meta">
        <span class="post-time"> 2023-09-02 </span>
        <div class="post-category">
            <a href="/categories/chatgpt/"> chatgpt </a>
            </div>
          <span class="more-meta"> 1972 words </span>
          <span class="more-meta"> 4 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#背景">背景</a></li>
        <li><a href="#策略1对用户提问做分类">策略1：对用户提问做分类</a></li>
        <li><a href="#策略2总结或者过滤长对话内容">策略2：总结或者过滤长对话内容</a></li>
        <li><a href="#策略3递归汇总长文档">策略3：递归汇总长文档</a></li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#references">References</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p><img src="/img/wechat.png" alt=""></p>
<h2 id="背景">背景</h2>
<p>OpenAI官方详细介绍了ChatGPT使用的最佳实践，不仅适用于使用ChatGPT网站进行直接对话的用户，还适用于通过OpenAI API接入的开发者。</p>
<p>掌握了这些最佳实践，就能更好地利用GPT大模型。</p>
<p>本文是ChatGPT使用最佳实践系列第3篇 - 将复杂任务拆分成更简单的子任务。</p>
<p>软件开发过程中，我们通常会把一个复杂的系统拆分成多个功能模块，这样整个系统更好理解，更容易维护。</p>
<p>这个原理同样适用于GPT大模型，因为复杂任务比简单任务有更高的错误率。如果把一个复杂的任务拆分成多个更为简单的子任务，大模型回答效果通常会更好。</p>
<h2 id="策略1对用户提问做分类">策略1：对用户提问做分类</h2>
<p>举个例子，如果你要做一个智能客服，用户的提问可能是非常多样的，有可能问产品信息，有有可能问技术问题，也有可能问账号信息等等。</p>
<p>为了能够精确回答客户的提问，我们可以先让大模型对用户的提问做分类，判断用户是在提问哪方面的问题。然后再根据用户提问的分类来给大模型输入对应的instruction指令，这样回答效果会更好。</p>
<p>参考如下示例：用户买了一个路由器，但是上不了网，于是用户做了如下提问</p>
<table>
<thead>
<tr>
<th>system</th>
<th>You will be provided with customer service queries. Classify each query into a primary category and a secondary category. Provide your output in json format with the keys: primary and secondary.<br/><br/>Primary categories: Billing, Technical Support, Account Management, or General Inquiry.<br/><br/>Billing secondary categories:<br/>- Unsubscribe or upgrade<br/>- Add a payment method<br/>- Explanation for charge<br/>- Dispute a charge<br/><br/>Technical Support secondary categories:<br/>- Troubleshooting<br/>- Device compatibility<br/>- Software updates<br/><br/>Account Management secondary categories:<br/>- Password reset<br/>- Update personal information<br/>- Close account<br/>- Account security<br/><br/>General Inquiry secondary categories:<br/>- Product information<br/>- Pricing<br/>- Feedback<br/>- Speak to a human</th>
</tr>
</thead>
<tbody>
<tr>
<td>user</td>
<td>I need to get my internet working again.</td>
</tr>
</tbody>
</table>
<p>我们可以通过system消息来让大模型先判断用户问题的分类，有了问题分类后，我们就可以把对应问题分类的instruction指令通过system消息告诉大模型，大模型再做回答。</p>
<table>
<thead>
<tr>
<th>system</th>
<th>You will be provided with customer service inquiries that require troubleshooting for technical support. Help the user by:<br/><br/>- Ask them to check that all cables to/from the router are connected. Note that it is common for cables to come loose over time.<br/>- If all cables are connected and the issue persists, ask them which router model they are using<br/>- Now you will advise them how to restart their device: <br/>&ndash; If the model number is MTD-327J, advise them to push the red button and hold it for 5 seconds, then wait 5 minutes before testing the connection.<br/>&ndash; If the model number is MTD-327S, advise them to unplug and replug it, then wait 5 minutes before testing the connection.<br/>- If the customer&rsquo;s issue persists after restarting the device and waiting 5 minutes, connect them to IT support by outputting {&ldquo;IT support requested&rdquo;}.<br/>- If the user starts asking questions that are unrelated to this topic then confirm if they would like to end the current chat about troubleshooting and classify their request according to the following scheme:<br/><br/>Classify their query into a primary category and a secondary category. Provide your output in json format with the keys: primary and secondary.<br/><br/>Primary categories: Billing, Technical Support, Account Management, or General Inquiry.<br/><br/>Billing secondary categories:<br/>- Unsubscribe or upgrade<br/>- Add a payment method<br/>- Explanation for charge<br/>- Dispute a charge<br/><br/>Technical Support secondary categories:<br/>- Troubleshooting<br/>- Device compatibility<br/>- Software updates<br/><br/>Account Management secondary categories:<br/>- Password reset<br/>- Update personal information<br/>- Close account<br/>- Account security<br/><br/>General Inquiry secondary categories:<br/>- Product information<br/>- Pricing<br/>- Feedback<br/>- Speak to a human</th>
</tr>
</thead>
<tbody>
<tr>
<td>user</td>
<td>I need to get my internet working again.</td>
</tr>
</tbody>
</table>
<ul>
<li>只要大模型输出的结果是分类结果，我们就根据分类结果来重新构造system消息，重新向大模型提问。</li>
<li>如果大模型输出的结果不是问题分类结果，那我们就不用改变system消息，直接把大模型的结果返回给用户即可。</li>
</ul>
<p>以上技术手段其实构造了一个状态机来回答用户的问题，非常适合于智能客服的场景。</p>
<p>可以通过这个链接地址进行体验：<a href="https://platform.openai.com/playground/p/default-decomposition-by-intent-classification-2">Open in Playground</a>。</p>
<h2 id="策略2总结或者过滤长对话内容">策略2：总结或者过滤长对话内容</h2>
<p>GPT大模型有上下文长度的限制，比如GPT-4最多只支持32k上下文长度，具体每个模型的上下文长度限制参考<a href="https://platform.openai.com/docs/models/gpt-4">context length</a>。</p>
<p>如果对话的轮次过多，或者对话内容过长(比如你让大模型帮你写论文等)，那把所有对话记录都发送给GPT就会超过GPT大模型的context length。</p>
<p>如何解决这个问题呢？有2个推荐的解决方案：</p>
<ul>
<li>第一种，设定一个token阈值，如果你发现对话记录的长度要超过这个阈值了，就可以把之前的部分对话记录让大模型做一个汇总，然后把汇总内容作为system消息给到大模型，这样就可以解决发送所有对话记录给大模型导致超过大模型上下文长度限制的问题。或者开发者的后台程序可以异步的对对话记录做定期汇总。</li>
<li>第二种，根据用户的提问，从对话记录里筛选出最相关的对话记录，减少要发送的token数量。可以通过向量化检索的方式来实现筛选逻辑，具体可以参考 <a href="https://platform.openai.com/docs/guides/gpt-best-practices/tactic-use-embeddings-based-search-to-implement-efficient-knowledge-retrieval">&ldquo;Use embeddings-based search to implement efficient knowledge retrieval&rdquo;</a>。</li>
</ul>
<h2 id="策略3递归汇总长文档">策略3：递归汇总长文档</h2>
<p>假设我们要对长文档(比如一本书)做汇总，由于大模型有上下文长度限制(假设为L)，在单次的请求里，假设大模型汇总后的结果completion的长度为A，那发给大模型的prompt的长度不能超过L-N。</p>
<p>completion结果的长度A我们是可以在API层面指定max_token参数来限制的，那怎么能控制prompt的长度呢？</p>
<p>我们可以对长文档的每一个章节分别做summary，然后对多个章节的summary继续递归summary，直到整篇长文档被summary。</p>
<p>要详细了解如何对长文档做summary可以参考OpenAI之前基于GPT-3变种的研究工作<a href="https://openai.com/research/summarizing-books">research</a>。</p>
<h2 id="总结">总结</h2>
<p>本文是ChatGPT使用最佳实践系列第3篇 - 将复杂任务拆分成更简单的子任务。</p>
<p>详细讲述了3个策略，以上策略不仅适用于GPT模型，还适用于其它大语言模型。</p>
<p>文章和示例代码开源在GitHub: <a href="https://github.com/jincheng9/gpt-tutorial">GPT实战教程</a>，可以看到所有主流的开源LLM。</p>
<p>公众号：coding进阶。关注公众号可以获取最新GPT实战内容。</p>
<p>个人网站：<a href="https://jincheng9.github.io/">Jincheng&rsquo;s Blog</a>。</p>
<p>知乎：<a href="https://www.zhihu.com/people/thucuhkwuji">无忌</a>。</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://platform.openai.com/docs/guides/gpt-best-practices">https://platform.openai.com/docs/guides/gpt-best-practices</a></li>
</ul>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/chatgpt/">chatgpt</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/chatgpt-12/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">ChatGPT最佳实践系列第4篇-给GPT思考的时间</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/chatgpt-10/">
            <span class="next-text nav-default">ChatGPT最佳实践系列-第2篇</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="jincheng9/jincheng9.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="https://github.com/jincheng9/" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thucuhkwuji" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="http://jincheng9.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2017 - 
    2023<span class="heart"><i class="iconfont icon-heart"></i></span><span>Jincheng9</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script><script></script><script src="https://cdn.jsdelivr.net/npm/raphael@2.2.7/raphael.min.js" integrity="sha256-67By+NpOtm9ka1R6xpUefeGOY8kWWHHRAKlvaTJ7ONI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/flowchart.js@1.8.0/release/flowchart.min.js" integrity="sha256-zNGWjubXoY6rb5MnmpBNefO0RgoVYfle9p0tvOQM+6k=" crossorigin="anonymous"></script><script></script><script src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" integrity="sha256-4O4pS1SH31ZqrSO2A/2QJTVjTPqVe+jnYgOWUVr7EEc=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/snapsvg@0.5.1/dist/snap.svg-min.js" integrity="sha256-oI+elz+sIm+jpn8F/qEspKoKveTc5uKeFHNNVexe6d8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/underscore@1.8.3/underscore-min.js" integrity="sha256-obZACiHd7gkOk9iIL/pimWMTJ4W/pBsKu+oZnSeBIek=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/gh/bramp/js-sequence-diagrams@2.0.1/dist/sequence-diagram-min.js" integrity="sha384-8748Vn52gHJYJI0XEuPB2QlPVNUkJlJn9tHqKec6J3q2r9l8fvRxrgn/E5ZHV0sP" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/bramp/js-sequence-diagrams@2.0.1/dist/sequence-diagram-min.css" integrity="sha384-6QbLKJMz5dS3adWSeINZe74uSydBGFbnzaAYmp+tKyq60S7H2p6V7g1TysM5lAaF" crossorigin="anonymous">



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>








</body>
</html>
